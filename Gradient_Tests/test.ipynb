{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cool2\n"
    }
   ],
   "source": [
    "####################################\n",
    "#LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "import pydde as dde\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "####################################\n",
    "#Parameters\n",
    "samplenum = 50\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "nTimeSteps = 10; #at 60 Hz\n",
    "model_file_path = '../Trained_Models/'\n",
    "data_file_path = '../Data/Samples/data_20k_2x2x2/'\n",
    "simulation_file_path = '../Data/Simulations/pointmass.sim'\n",
    "objective_file_path = '../Data/Objectives/pointmass.opt'\n",
    "\n",
    "#######################################\n",
    "# LOAD SIMULATION AND OBJECTIVE FUNCTION\n",
    "dyn = dde.DynamicSequence()\n",
    "dyn.loadFile(simulation_file_path, nTimeSteps)\n",
    "p_init = np.zeros(dyn.p0.size*nTimeSteps)\n",
    "for i in range(nTimeSteps):\n",
    "\tp_init[i*dyn.p0.size : (i+1)*dyn.p0.size] = dyn.p0\n",
    "\n",
    "#############################################\n",
    "#LOAD OBJECTIVE PYDDE_V2\n",
    "obj = dde.InverseObjective(dyn)\n",
    "obj.loadFile(objective_file_path)\n",
    "objective_json = json.load(open(objective_file_path))\n",
    "\n",
    "#############################################\n",
    "#GENERATE OPTIMIZATION PYDDE_V2\n",
    "opt = dde.Newton()\n",
    "\n",
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum, 3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "print('cool2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#USE P FROM TRAJ_OPT\n",
    "p = np.ones((3*nTimeSteps, samplenum))\n",
    "for i in range(samplenum):\n",
    "    objective_json[\"objectives\"][\"pmTargetPositions\"][0][\"targetPos\"] = ([[y_target[i,0]],[y_target[i,1]],[y_target[i,2]]]) \n",
    "    obj.loadJson(objective_json)\n",
    "    p[:,i] = opt.minimize(obj, p_init)\n",
    "print('hello')\n",
    "p = torch.tensor(p, requires_grad = True).t()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['/Users/nicovonau/Code/thesis_pytorch/Examples', '/private/var/folders/fg/z9hxlwkx7dl424b9sm5btqmh0000gn/T/cbe117fc-46b2-4cfe-b7bd-e90c47981a88', '/Users/nicovonau/.vscode/extensions/ms-python.python-2020.6.91350/pythonFiles', '/Users/nicovonau/.vscode/extensions/ms-python.python-2020.6.91350/pythonFiles/lib/python', '/Users/nicovonau/anaconda3/lib/python37.zip', '/Users/nicovonau/anaconda3/lib/python3.7', '/Users/nicovonau/anaconda3/lib/python3.7/lib-dynload', '', '/Users/nicovonau/anaconda3/lib/python3.7/site-packages', '/Users/nicovonau/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/nicovonau/pathpy', '/Users/nicovonau/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/Users/nicovonau/.ipython']\n"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([2, 9])\n"
    }
   ],
   "source": [
    "# Generate simulation, random p\n",
    "dyn = d.PyDyn('../Data/point-mass_pendulum.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)\n",
    "\n",
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum, 3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "#print(y_target)\n",
    "p = np.ones((3*time_length, samplenum))\n",
    "for i in range(samplenum):\n",
    "    p[:,i] = dyn.get_p(y_target.transpose()[:,i], dyn.p_init)\n",
    "p = torch.tensor(p, requires_grad = True).t()\n",
    "input = p.double()\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#BUILD CUSTOM FUNCTION\n",
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        y_pred = torch.ones([samplenum,3])\n",
    "        for i in range(len(p[0, :])):\n",
    "            state = dyn.compute(p[:,i])\n",
    "            y_pred[i, :] = torch.tensor(state.y[-3:])\n",
    "        print(f'y_pred: {y_pred}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        dy_dp_batch = torch.zeros([3, 3*time_length])\n",
    "        for i in range(samplenum):\n",
    "            state= dyn.compute(p[:, i])\n",
    "            dy_dp = dyn.dy_dp(state, p[:, i])\n",
    "            dy_dp = torch.tensor(dy_dp[-3:, :])\n",
    "            dy_dp_batch = dy_dp_batch + dy_dp\n",
    "        print(f'shape of dy/dp_batch: {dy_dp_batch.dtype}')\n",
    "        \n",
    "        grad_input = torch.tensor(grad_output.double().mm(dy_dp_batch/samplenum))\n",
    "        print(f'shape of grad input: {grad_input.shape}')\n",
    "        print(f'shape of grad output: {grad_output.shape}')\n",
    "        print(f'grad_input: {grad_input}')\n",
    "        print(f'grad_output: {grad_output}')\n",
    "        return grad_input    \n",
    "\n",
    "Simulate = Simulate.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[1., 0., 0.]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[1., 0., 0.]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 1., 0.]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 1., 0.]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 1.]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 1.]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[5.3478e-06, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[3.7764e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1554e-05, 1.9998e+00, 0.0000e+00]])\ny_pred: tensor([[2.1559e-05, 1.9996e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -1.6208e-05]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 1.6208e-05]])\ny_pred: tensor([[1.0711e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[3.2401e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1564e-05, 1.9993e+00, 0.0000e+00]])\ny_pred: tensor([[2.1549e-05, 2.0001e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -1.0845e-05]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 1.0845e-05]])\ny_pred: tensor([[1.6119e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.6993e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1595e-05, 1.9979e+00, 0.0000e+00]])\ny_pred: tensor([[2.1518e-05, 2.0015e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -5.4371e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 5.4371e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00]])\nshape of dy/dp_batch: torch.float64\nshape of grad input: torch.Size([1, 9])\nshape of grad output: torch.Size([1, 3])\ngrad_input: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.]])\nTrue\n"
    }
   ],
   "source": [
    "#GRADCHECK\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "test = gradcheck(Simulate, (input,), eps=2e-3, atol=1e-4, raise_exception = True)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda39d998b0540f4e659e09acca95c25f2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}