{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 4\n",
    "epochs = 5\n",
    "hiddenlayers = [90]\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "learning_rate = 0.001\n",
    "time_length = 5; #seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulation\n",
    "dyn = d.PyDyn('Data/point-mass_pendulum.sim', time_length)\n",
    "#dyn = d.PyDyn('Data/rb-pendulum/twoRb.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.0000, 2.0000, 0.0763],\n        [0.0000, 2.0000, 0.9818],\n        [0.0000, 2.0000, 0.3835],\n        [0.0000, 2.0000, 0.8418]], dtype=torch.float64)"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum,3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "y_target= torch.tensor(y_target)\n",
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the custon Simulation activation function and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input.shape}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        y_pred = torch.ones([samplenum,3])\n",
    "        for i in range(len(p[0, :])):\n",
    "            state = dyn.compute(p[:,i])\n",
    "            y_pred[i, :] = torch.tensor(state.y[-3:])\n",
    "        #print(f'y_pred: {y_pred.shape}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print(f'grad output = {grad_output.shape}')\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        dy_dp_batch = torch.ones([3, samplenum*3*time_length])\n",
    "        for i in range(len(p[0, :])):\n",
    "            #index = torch.arange(i*3*time_length, i*3*time_length+3*time_length)\n",
    "            state= dyn.compute(p[:, i])\n",
    "            dy_dp = dyn.dy_dp(state, p[:, i])\n",
    "            dy_dp = torch.tensor(dy_dp[-3:, :])\n",
    "            print(f'dy_dp = {dy_dp.shape}')\n",
    "            dy_dp_batch[:, (i*3*time_length):(i*3*time_length+(3*time_length))] = dy_dp\n",
    "        print(f'shape of dy/dp_batch: {dy_dp_batch.shape}')\n",
    "        \n",
    "        grad_input = torch.tensor(dy_dp_batch).t().mm(grad_output.t())\n",
    "        print(f'shape of grad input: {grad_input.shape}')\n",
    "        return grad_input\n",
    "\n",
    "Simulate = Simulate.apply\n",
    "\n",
    "class ActiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(ActiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(n_in, hiddenlayers[0])\n",
    "        self.H1 = nn.Linear(hiddenlayers[0], 3*time_length)\n",
    "        #self.H1 = nn.Linear(hiddenlayers[0], hiddenlayers[1])\n",
    "        #self.H2 = nn.Linear(hiddenlayers[1], 3*time_length)\n",
    "        self.P = nn.Linear(3*time_length, 3*time_length)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H1(x)\n",
    "        x = self.Relu(x)\n",
    "        #x = self.H2(x)\n",
    "        #x = self.Relu(x)\n",
    "        x = self.P(x)\n",
    "        x = self.Relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ActiveLearn(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()  # RMSE = np.sqrt(MSE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "y_target = y_target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "input: torch.Size([4, 15])\n[[0.         0.         0.         0.        ]\n [0.19863126 0.14947447 0.1638604  0.18559146]\n [0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.25616917 0.2295226  0.24310282 0.25499287]\n [0.         0.         0.         0.        ]\n [0.03689428 0.         0.         0.02426878]\n [0.11494696 0.07961529 0.095068   0.11199307]\n [0.08668315 0.10223247 0.10192344 0.09625881]\n [0.         0.         0.         0.        ]\n [0.17958242 0.13337764 0.14984947 0.17250447]\n [0.20030531 0.10532123 0.13499646 0.17711805]\n [0.1168789  0.07053249 0.09257828 0.11364429]\n [0.         0.         0.         0.        ]\n [0.20760596 0.20938584 0.21173942 0.21158448]]\ny_pred: tensor([[ 1.4895e-02,  9.8974e-01, -1.6985e-02],\n        [ 9.6590e-03,  9.9358e-01, -6.5585e-04],\n        [ 1.3374e-02,  9.9232e-01, -3.4950e-03],\n        [ 1.5946e-02,  9.9072e-01, -1.0351e-02]])\n"
    }
   ],
   "source": [
    "p_pred = model(y_target)\n",
    "print(f'input: {p_pred.shape}')\n",
    "p = p_pred.detach().numpy().transpose()\n",
    "print(p)\n",
    "y_pred = torch.ones([samplenum,3])\n",
    "for i in range(len(p[0, :])):\n",
    "    state = dyn.compute(p[:,i])\n",
    "    y_pred[i, :] = torch.tensor(state.y[-3:])\n",
    "print(f'y_pred: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "grad output = torch.Size([4, 3])\ndy_dp = torch.Size([3, 15])\ndy_dp = torch.Size([3, 15])\ndy_dp = torch.Size([3, 15])\ndy_dp = torch.Size([3, 15])\nshape of dy/dp_batch: torch.Size([3, 60])\nshape of grad input: torch.Size([60, 4])\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Function SimulateBackward returned an invalid gradient at index 0 - got [60, 4] but expected shape compatible with [4, 15]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2005deeea928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#Back Prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function SimulateBackward returned an invalid gradient at index 0 - got [60, 4] but expected shape compatible with [4, 15]"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "y_preds= np.zeros((samplenum, 3))\n",
    "p_preds= np.zeros((samplenum, 3*time_length))\n",
    "y_pred = torch.tensor([samplenum,3])\n",
    "for i in range(epochs):\n",
    "    p_pred = model(y_target)\n",
    "    y_pred = Simulate(p_pred)\n",
    "    #print(f'shape of y_pred: {y_pred.shape}')\n",
    "    loss = torch.sqrt(criterion(y_pred.float(), y_target)) # RMSE\n",
    "    #loss = criterion(y_pred.float(), y_truth) + 0.2*(sum(p[0:3]-dyn.p_init[0:3]))**2  # MSE + start condition penalty + p smoothness condition penalty\n",
    "    #loss =sum((y_pred.float()-y_truth)**2) \n",
    "    optimizer.zero_grad()\n",
    "    #Back Prop\n",
    "    loss.backward()\n",
    "    #optimizer.step()\n",
    "    print(f'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}')\n",
    "    #i+=1\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.3f} min') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model saved\n"
    }
   ],
   "source": [
    "#Save Model\n",
    "\n",
    "if len(losses) == epochs*(samplenum):\n",
    "    torch.save(model.state_dict(), 'Trained_Model_300420_300s_100e_onlyZpos.pt')\n",
    "    print('Model saved')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.0944146 1.9530724 0.3841143]\ntensor([0.0000, 2.0000, 0.5000])\n[0.0944146 1.9530724 0.3841143]\n0.0\n[0.         0.         0.         0.         0.         0.20432281\n 0.         0.         1.451682   1.3087382  0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         1.6551723  0.         0.         0.\n 0.         0.         0.07099061 0.         0.         0.\n 0.         0.         0.         0.25406152 0.         0.\n 0.         0.         0.         1.1448839  1.0023524  0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.07773931 0.         0.         0.         0.1156168\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.5394917  0.         0.40568525 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.01849897 0.         0.26445943 0.         0.\n 0.         0.         0.         0.         0.         1.8941786\n 0.         0.         0.         0.         0.         0.\n 0.5330909  0.         0.         0.         0.         0.\n 1.5261192  0.         0.         0.         0.         0.71748024\n 0.         0.25342453 0.         0.47286656 0.         1.4034631\n 0.         1.133931   0.         0.16180235 0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.3257668  0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.38985682 0.59257495 0.         0.         0.\n 0.9095051  0.7258321  0.         0.         0.         0.\n 0.         0.         0.52319086 0.         0.         0.\n 0.         0.         0.         0.         0.         0.36893564\n 0.         0.6136531  0.         0.         0.6773176  0.\n 0.         0.         1.9948217  0.         0.         0.\n 0.32203013 0.5084514  0.         0.         3.027595   0.        ]\n"
    }
   ],
   "source": [
    "y_target= torch.tensor([0, 2, 0.5])\n",
    "p = model(y_target)\n",
    "y_pred = Simulate(p)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "p = p.detach().numpy()\n",
    "\n",
    "\n",
    "yTraj_test = dyn.compute(p)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_target)\n",
    "print(yTraj_test.y[-3:])\n",
    "print(np.sum(yTraj_test.y[-3:]-y_pred))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Script Conversion and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.9574, 0.0000, 0.0000, 2.7701, 0.0000], grad_fn=<SliceBackward>)\n"
    }
   ],
   "source": [
    "input_example = torch.tensor(y_target[0,:])\n",
    "traced_script_module = torch.jit.trace(model, input_example)\n",
    "original = model(test_input)\n",
    "\n",
    "# Test the torch script\n",
    "test_input= torch.tensor([0, 2, 0.5])\n",
    "output_example = traced_script_module(test_input)\n",
    "print(output_example[-12:])\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized model\n",
    "traced_script_module.save(\"CPP_example_model_latest.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "y_pred = torch.ones([samplenum,3])\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}