{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 5\n",
    "batchsize = samplenum\n",
    "epochs = 500\n",
    "time_length = 60; #seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate simulation\n",
    "sim = d.PySimSeq('test2.sim', time_length)\n",
    "ySeq = sim.compute(sim.p)\n",
    "f = sim.f(sim.y, sim.ydot, sim.yddot, sim.p)\n",
    "df = sim.df_dp(sim.y, sim.ydot, sim.yddot, sim.p)\n",
    "ySeq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.        , 0.79004199],\n",
       "       [0.        , 2.        , 0.18758779],\n",
       "       [0.        , 2.        , 0.62876515],\n",
       "       [0.        , 2.        , 0.78892204],\n",
       "       [0.        , 2.        , 0.62024301]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample targets only variables in z direction\n",
    "x = np.zeros((samplenum,3))\n",
    "x[:,2] = np.random.rand(samplenum)\n",
    "#x[:,0] = np.random.rand(samplenum)\n",
    "x[:,1] = 2\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duration: 0.149 min\n"
     ]
    }
   ],
   "source": [
    "#Sample ptraj\n",
    "start_time1 = time.time()\n",
    "y = np.zeros((samplenum, 3*time_length))\n",
    "for i in range(samplenum):\n",
    "    y[i, :] = sim.sample_ptraj(x[i, :], sim.p)\n",
    "\n",
    "print(f'\\nDuration: {(time.time() - start_time1)/60:.3f} min') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesing\n",
    "x= torch.tensor(x)\n",
    "y= torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 180])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dataset = Dataset(x,y)\n",
    "\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = batchsize, shuffle = True)\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz, hlayers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bnorm = nn.BatchNorm1d(n_in)\n",
    "\n",
    "        layerlist = []\n",
    "\n",
    "        for i in hlayers:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(hlayers[-1],out_sz))\n",
    "\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.bnorm(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=200, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): Linear(in_features=100, out_features=180, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Define Model\n",
    "model = Model(x.shape[1], y.shape[1], [200,100])\n",
    "\n",
    "criterion = nn.MSELoss()  # RMSE = np.sqrt(MSE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Test/Train data\n",
    "#batch_size = 2\n",
    "#test_size = int(batch_size * .2)\n",
    "\n",
    "# cat_train = cats[:batch_size-test_size]\n",
    "# cat_test = cats[batch_size-test_size:batch_size]\n",
    "# con_train = conts[:batch_size-test_size]\n",
    "# con_test = conts[batch_size-test_size:batch_size]\n",
    "#y_train = y[:batch_size-test_size]\n",
    "#y_test = y[batch_size-test_size:batch_size]\n",
    "x_train = x.float()\n",
    "y_train = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1/500  loss: 1.82144845\n",
      "epoch:  26/500  loss: 0.39382920\n",
      "epoch:  51/500  loss: 0.11501388\n",
      "epoch:  76/500  loss: 0.05033321\n",
      "epoch: 101/500  loss: 0.03731985\n",
      "epoch: 126/500  loss: 0.03796473\n",
      "epoch: 151/500  loss: 0.02758416\n",
      "epoch: 176/500  loss: 0.02679308\n",
      "epoch: 201/500  loss: 0.02491123\n",
      "epoch: 226/500  loss: 0.03305647\n",
      "epoch: 251/500  loss: 0.02083281\n",
      "epoch: 276/500  loss: 0.04825019\n",
      "epoch: 301/500  loss: 0.04706486\n",
      "epoch: 326/500  loss: 0.03616522\n",
      "epoch: 351/500  loss: 0.03600014\n",
      "epoch: 376/500  loss: 0.03080637\n",
      "epoch: 401/500  loss: 0.03649246\n",
      "epoch: 426/500  loss: 0.02524248\n",
      "epoch: 451/500  loss: 0.03338098\n",
      "epoch: 476/500  loss: 0.02643787\n",
      "epoch: 500 loss: 0.03609372\n",
      "\n",
      "Duration: 4 seconds\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    for inputs,labels in train_loader:\n",
    "        x_train = inputs.float()\n",
    "        y_train = labels.float()\n",
    "        i+=1\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "        losses.append(loss)\n",
    "\n",
    "        if i%25 == 1:\n",
    "            print(f'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}')\n",
    "\n",
    "        #Clear the gradient buffer (w <-- w - lr*gradient)\n",
    "        optimizer.zero_grad()\n",
    "        #Back Prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-114-743b15137b18>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-114-743b15137b18>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "\n",
    "if len(losses) == epochs*(samplenum/batchsize):\n",
    "    print('saving...')\n",
    "    #torch.save(model.state_dict(), 'Trained_Model5000.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
