{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 2\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "time_length = 3; #ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 3., 0., 0., 3., 0., 0., 3., 0.],\n        [0., 3., 0., 0., 3., 0., 0., 3., 0.]], dtype=torch.float64,\n       grad_fn=<TBackward>)\n"
    }
   ],
   "source": [
    "# Generate simulation\n",
    "dyn = d.PyDyn('../Data/point-mass_pendulum.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)\n",
    "#sample p\n",
    "p = np.ones((3*time_length, samplenum))\n",
    "p[:,0] = dyn.p_init\n",
    "if samplenum != 1:\n",
    "    p[:,1] =p[:,0]\n",
    "p = torch.tensor(p, requires_grad = True).t()\n",
    "input = p.double()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the custon Simulation Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        y_pred = torch.ones([samplenum,3])\n",
    "        for i in range(len(p[0, :])):\n",
    "            state = dyn.compute(p[:,i])\n",
    "            y_pred[i, :] = torch.tensor(state.y[-3:])\n",
    "        print(f'y_pred: {y_pred}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        dy_dp_batch = torch.zeros([3, 3*time_length])\n",
    "        for i in range(samplenum):\n",
    "            state= dyn.compute(p[:, i])\n",
    "            dy_dp = dyn.dy_dp(state, p[:, i])\n",
    "            dy_dp = torch.tensor(dy_dp[-3:, :])\n",
    "            dy_dp_batch = dy_dp_batch + dy_dp\n",
    "        print(f'shape of dy/dp_batch: {dy_dp_batch.shape}')\n",
    "        \n",
    "        grad_input = torch.tensor(grad_output.double().mm(dy_dp_batch))/samplenum\n",
    "        print(f'shape of grad input: {grad_input.shape}')\n",
    "        print(f'shape of grad output: {grad_output.shape}')\n",
    "        print(f'grad_input: {grad_input}')\n",
    "        print(f'grad_output: {grad_output}')\n",
    "        return grad_input    \n",
    "\n",
    "Simulate = Simulate.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[1., 0., 0.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[1., 0., 0.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 1., 0.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 1., 0.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 1.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 1.],\n        [0., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [1., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 8.0987e-03,  1.4527e-06,  0.0000e+00,  5.4188e-03, -3.7828e-06,\n          0.0000e+00,  2.7168e-03, -1.9345e-05,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [1., 0., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [0., 1., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 1.3361e-06, -5.3950e-02,  0.0000e+00, -3.7514e-06,  1.7934e-01,\n          0.0000e+00, -1.9345e-05,  9.0041e-01,  0.0000e+00]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [0., 1., 0.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [0., 0., 1.]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0081, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0027]],\n       dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [0., 0., 1.]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[1.3456e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.9656e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1555e-05, 1.9998e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1558e-05, 1.9996e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -8.1001e-06],\n        [ 2.1556e-05,  1.9997e+00,  0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 8.1001e-06],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[1.6136e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.6976e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1560e-05, 1.9995e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1552e-05, 1.9999e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -5.4197e-06],\n        [ 2.1556e-05,  1.9997e+00,  0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 5.4197e-06],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[1.8839e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.4273e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1576e-05, 1.9988e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1537e-05, 2.0006e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00, -2.7172e-06],\n        [ 2.1556e-05,  1.9997e+00,  0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 2.7172e-06],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [1.3456e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.9656e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1555e-05, 1.9998e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1558e-05, 1.9996e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00,  0.0000e+00],\n        [ 2.1556e-05,  1.9997e+00, -8.1001e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 8.1001e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [1.6136e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.6976e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1560e-05, 1.9995e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1552e-05, 1.9999e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00,  0.0000e+00],\n        [ 2.1556e-05,  1.9997e+00, -5.4197e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 5.4197e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [1.8839e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.4273e-05, 1.9997e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1576e-05, 1.9988e+00, 0.0000e+00]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1537e-05, 2.0006e+00, 0.0000e+00]])\ny_pred: tensor([[ 2.1556e-05,  1.9997e+00,  0.0000e+00],\n        [ 2.1556e-05,  1.9997e+00, -2.7172e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 2.7172e-06]])\ny_pred: tensor([[2.1556e-05, 1.9997e+00, 0.0000e+00],\n        [2.1556e-05, 1.9997e+00, 0.0000e+00]])\nshape of dy/dp_batch: torch.Size([3, 9])\nshape of grad input: torch.Size([2, 9])\nshape of grad output: torch.Size([2, 3])\ngrad_input: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\ngrad_output: tensor([[0., 0., 0.],\n        [0., 0., 0.]])\nTrue\n"
    }
   ],
   "source": [
    "#GRADCHECK\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "test = gradcheck(Simulate, (input,), eps=1e-3, atol=1e-3, raise_exception = True)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8.100000000000002e-06"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#print(p.backward(torch.ones(samplenum,9)))\n",
    "p.requires_grad\n",
    "2.1556e-05-1.3456e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45c188ded2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 'then all other inputs should have requires_grad=True.')\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mfunc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtupled_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_differentiable_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "from torch.autograd import gradcheck\n",
    "p = torch.tensor(p, requires_grad = True).t()\n",
    "input = (p.double())\n",
    "test = nn.Linear(9,3)\n",
    "#print(input)\n",
    "test = gradcheck(test, (input,), eps=1e-3, atol=1e-3, raise_exception = True)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}