{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 10\n",
    "epochs = 20\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "learning_rate = 0.01\n",
    "time_length = 3; #seconds\n",
    "hiddenlayers = [90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.         2.         0.2207534 ]\n [0.         2.         0.27073957]\n [0.         2.         0.11730403]\n [0.         2.         0.74790176]\n [0.         2.         0.90423131]\n [0.         2.         0.51426679]\n [0.         2.         0.4208993 ]\n [0.         2.         0.26617991]\n [0.         2.         0.32218653]\n [0.         2.         0.87319777]]\n(9, 10)\n"
    }
   ],
   "source": [
    "# Generate simulation\n",
    "dyn = d.PyDyn('../Data/point-mass_pendulum.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)\n",
    "\n",
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum, 3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "print(y_target)\n",
    "p = np.ones((3*time_length, samplenum))\n",
    "for i in range(samplenum):\n",
    "    p[:,i] = dyn.get_p(y_target.transpose()[:,i], dyn.p_init)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the custon Simulation Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input.shape}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        y_pred = torch.ones([samplenum,3])\n",
    "        for i in range(len(p[0, :])):\n",
    "            state = dyn.compute(p[:,i])\n",
    "            y_pred[i, :] = torch.tensor(state.y[-3:])\n",
    "        #print(f'y_pred: {y_pred.shape}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print(grad_output)\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        dy_dp_batch = torch.zeros([3, 3*time_length])\n",
    "        for i in range(samplenum):\n",
    "            state= dyn.compute(p[:, i])\n",
    "            dy_dp = dyn.dy_dp(state, p[:, i])\n",
    "            dy_dp = torch.tensor(dy_dp[-3:, :])\n",
    "            dy_dp_batch = dy_dp_batch + dy_dp\n",
    "        print(f'shape of dy/dp_batch: {dy_dp_batch.shape}')\n",
    "        \n",
    "        grad_input = torch.tensor(dy_dp_batch/samplenum).t().mm(grad_output.t().double()).t()\n",
    "        #print(f'shape of grad input: {grad_input.shape}')\n",
    "        #print(f'shape of grad output: {grad_output.shape}')\n",
    "        return grad_input\n",
    "\n",
    "Simulate = Simulate.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE Test for custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([10, 3])\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\nshape of dy/dp_batch: torch.Size([3, 9])\ndy_dp shape = torch.Size([9, 10])\ndy_dp = tensor([[-2.9386e-04, -2.9386e-04, -2.9386e-04, -2.9386e-04, -2.9386e-04,\n         -2.9386e-04, -2.9386e-04, -2.9386e-04, -2.9386e-04, -2.9386e-04],\n        [-9.1943e-02, -9.1943e-02, -9.1943e-02, -9.1943e-02, -9.1943e-02,\n         -9.1943e-02, -9.1943e-02, -9.1943e-02, -9.1943e-02, -9.1943e-02],\n        [ 1.5787e-04,  1.5787e-04,  1.5787e-04,  1.5787e-04,  1.5787e-04,\n          1.5787e-04,  1.5787e-04,  1.5787e-04,  1.5787e-04,  1.5787e-04],\n        [ 1.1461e-02,  1.1461e-02,  1.1461e-02,  1.1461e-02,  1.1461e-02,\n          1.1461e-02,  1.1461e-02,  1.1461e-02,  1.1461e-02,  1.1461e-02],\n        [ 1.6780e-01,  1.6780e-01,  1.6780e-01,  1.6780e-01,  1.6780e-01,\n          1.6780e-01,  1.6780e-01,  1.6780e-01,  1.6780e-01,  1.6780e-01],\n        [ 1.3472e-02,  1.3472e-02,  1.3472e-02,  1.3472e-02,  1.3472e-02,\n          1.3472e-02,  1.3472e-02,  1.3472e-02,  1.3472e-02,  1.3472e-02],\n        [ 1.3456e-02,  1.3456e-02,  1.3456e-02,  1.3456e-02,  1.3456e-02,\n          1.3456e-02,  1.3456e-02,  1.3456e-02,  1.3456e-02,  1.3456e-02],\n        [ 9.2347e-01,  9.2347e-01,  9.2347e-01,  9.2347e-01,  9.2347e-01,\n          9.2347e-01,  9.2347e-01,  9.2347e-01,  9.2347e-01,  9.2347e-01],\n        [ 4.1219e-02,  4.1219e-02,  4.1219e-02,  4.1219e-02,  4.1219e-02,\n          4.1219e-02,  4.1219e-02,  4.1219e-02,  4.1219e-02,  4.1219e-02]],\n       dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# Error for whole simulation\n",
    "from numpy import linalg as LA\n",
    "\n",
    "FE = 1e-6\n",
    "p = torch.tensor(p, requires_grad = True).double()\n",
    "y = Simulate(p.t())\n",
    "print(y.shape)\n",
    "#test = sum(y)\n",
    "#test.backward()\n",
    "grad_output = torch.ones([10,3]).double()\n",
    "y.backward(grad_output)\n",
    "dy_dp = p.grad.double()\n",
    "print(f'dy_dp shape = {p.grad.shape}')\n",
    "print(f'dy_dp = {dy_dp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dp_FD = np.zeros((samplenum,len(dyn.p_init)))\n",
    "#dy_dp_FD = np.zeros((3,len(dyn.p_init)))\n",
    "\n",
    "for i in range(len(dyn.p_init)):\n",
    "    dp= np.zeros(len(dyn.p_init))\n",
    "    dp[i] = FE\n",
    "    dp = torch.tensor(dp)\n",
    "    y_p = Simulate(p + dp)\n",
    "    y_m = Simulate(p - dp)\n",
    "    y_p = y_p.detach().numpy()\n",
    "    y_m = y_m.detach().numpy()\n",
    "    dy_dp_FD[0, i] = sum((y_p - y_m) / (2* FE))\n",
    "    #dy_dp_FD[:, i] = (y_p - y_m) / (2* FE)\n",
    "\n",
    "\n",
    "print(f' dy_dp_FD = {dy_dp_FD}')\n",
    "print(f' dy_dp_FD = {dy_dp_FD.shape}')\n",
    "dy_dp = dy_dp.detach().numpy()\n",
    "err = LA.norm(dy_dp_FD - dy_dp)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FD Test for dy_dp Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.5942135105905507e-06\n"
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "#Calculate dy_dp with FE\n",
    "FE = 1e-6\n",
    "dy_dp = dyn.dy_dp(state_init, dyn.p_init)\n",
    "dy_dp_FD = np.zeros((len(dyn.p_init),len(dyn.p_init)))\n",
    "\n",
    "for i in range(len(dyn.p_init)):\n",
    "    dp= np.zeros(len(dyn.p_init))\n",
    "    dp[i] = FE\n",
    "    pos = dyn.p_init + dp\n",
    "    y_p = dyn.compute(pos)\n",
    "    y_m = dyn.compute(dyn.p_init - dp)\n",
    "    dy_dp_FD[:, i] = (y_p.y - y_m.y) / (2* FE)\n",
    "err = LA.norm(dy_dp_FD - dy_dp)\n",
    "print(err)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit9cd58f39d82e4726a1557beda61fb6da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}