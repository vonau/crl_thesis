{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 3\n",
    "batchsize = samplenum\n",
    "epochs = 50\n",
    "input_size = 3\n",
    "output_size = 180\n",
    "learning_rate = 0.01\n",
    "time_length = 60; #seconds\n",
    "\n",
    "# Generate simulation\n",
    "sim = d.PySimSeq('test2.sim', 60)\n",
    "yseq = sim.compute(sim.p)\n",
    "f = sim.f(sim.y, sim.ydot, sim.yddot, sim.p)\n",
    "df = sim.df_dp(sim.y, sim.ydot, sim.yddot, sim.p)\n",
    "\n",
    "#Sample targets only variables in z direction\n",
    "x = np.zeros((samplenum,3))\n",
    "x[:,2] = np.random.rand(samplenum)\n",
    "x[:,1] = 2\n",
    "p = np.zeros((samplenum, 3*time_length))\n",
    "y = np.zeros((samplenum, 3*time_length))\n",
    "\n",
    "for i in range(samplenum):\n",
    "    p[i, :] = sim.sample_ptraj(x[i, :], sim.p)\n",
    "    y[i, :] = sim.compute(p[i, :].transpose())\n",
    "    \n",
    "x= torch.tensor(x)\n",
    "y= torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, y_target):\n",
    "        #print(input.shape)\n",
    "        #print(y_target.shape)\n",
    "        #ctx.mark_dirty( y_target)\n",
    "        p = input.clone().numpy().transpose()\n",
    "        y_target = y_target.clone().numpy()\n",
    "        #print(p.shape)\n",
    "        #print(y_target.shape)\n",
    "        yTraj_pred = np.zeros((len(y_target[:, 1]),180))\n",
    "        \n",
    "        for i in range(len(y_target[:,1])):\n",
    "            yTraj_pred[i, :] = sim.compute(p[:, i])\n",
    "\n",
    "        yTraj_pred = torch.tensor(yTraj_pred)\n",
    "        #print(f'yTraj_pred {yTraj_pred.shape}')\n",
    "        \n",
    "        ctx.save_for_backward(input, yTraj_pred)\n",
    "        \n",
    "        return yTraj_pred, input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, input):\n",
    "        input, yTraj_pred = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        yTraj_pred = yTraj_pred.clone().numpy()\n",
    "        dy_dp = np.zeros((samplenum, 3*time_length))\n",
    "        for i in range(len(yTraj_pred[:,1])):\n",
    "            yTraj_pred[i, :] = sim.compute(p[:, i])\n",
    "        dy_dp = sim.dy_dp(sim.y, sim.ydot, sim.yddot, p[:, i])\n",
    "        #print(dy_dp)\n",
    "        print(f'shape of grad_output: {grad_output.shape}')\n",
    "\n",
    "        \n",
    "        grad_input = torch.tensor(dy_dp).mm(grad_output.t()).t()\n",
    "        return grad_input, None\n",
    "\n",
    "Simulate = Simulate.apply\n",
    "\n",
    "class ActiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(ActiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(input_size, output_size)\n",
    "        self.P = nn.Linear(output_size, output_size)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.P(x)\n",
    "        x = self.Relu(x)\n",
    "        x, p = Simulate(x, input)\n",
    "        return x, p\n",
    "\n",
    "model = ActiveLearn(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()  # RMSE = np.sqrt(MSE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "x_train = x.float()\n",
    "y_train = y.float()\n",
    "y_target = x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   0/50  loss: 1.34852377\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   1/50  loss: 1.07913504\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   2/50  loss: 1.06361814\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   3/50  loss: 1.08703434\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   4/50  loss: 1.15299966\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   5/50  loss: 1.29066155\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   6/50  loss: 1.29729090\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   7/50  loss: 1.30667444\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   8/50  loss: 1.33294105\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:   9/50  loss: 1.22715179\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  10/50  loss: 1.08148110\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  11/50  loss: 1.04442154\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  12/50  loss: 0.92819345\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  13/50  loss: 0.82476692\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  14/50  loss: 0.84878708\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  15/50  loss: 0.77732292\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  16/50  loss: 0.71140377\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  17/50  loss: 0.66534101\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  18/50  loss: 0.63383048\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  19/50  loss: 0.63572797\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  20/50  loss: 0.68804259\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  21/50  loss: 0.67455293\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  22/50  loss: 0.63078678\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  23/50  loss: 0.62916273\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  24/50  loss: 0.73706341\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  25/50  loss: 0.54438019\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  26/50  loss: 0.52544502\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  27/50  loss: 0.49965186\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  28/50  loss: 0.44011365\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  29/50  loss: 0.42759771\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  30/50  loss: 0.36765387\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  31/50  loss: 0.35238005\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  32/50  loss: 0.32049385\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  33/50  loss: 0.33105723\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  34/50  loss: 0.35603622\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  35/50  loss: 0.38481298\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  36/50  loss: 0.35477207\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  37/50  loss: 0.29641842\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  38/50  loss: 0.23513806\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  39/50  loss: 0.24464070\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  40/50  loss: 0.20078010\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  41/50  loss: 0.26765351\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  42/50  loss: 0.28002946\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  43/50  loss: 0.19484513\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  44/50  loss: 0.24384305\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  45/50  loss: 0.21965588\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  46/50  loss: 0.36645456\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  47/50  loss: 0.19146767\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  48/50  loss: 0.23798193\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "torch.float64\n",
      "torch.float32\n",
      "epoch:  49/50  loss: 0.19770378\n",
      "shape of grad_output: torch.Size([3, 180])\n",
      "epoch:  50 loss: 0.19770378\n",
      "\n",
      "Duration: 0.890 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred, p_pred = model(x_train)\n",
    "    print(y_pred.dtype)\n",
    "    print(x_train.dtype)\n",
    "    #loss = torch.sqrt(criterion(y_pred, y)) # RMSE\n",
    "    loss = criterion(y_pred, y) # RMSE\n",
    "    losses.append(loss)\n",
    "\n",
    "    print(f'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    #Clear the gradient buffer (w <-- w - lr*gradient)\n",
    "    optimizer.zero_grad()\n",
    "    #Back Prop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    i+=1\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.3f} min') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1368683772161603e-13\n"
     ]
    }
   ],
   "source": [
    "#Test forward propagation\n",
    "\n",
    "p_pred = p_pred.detach().numpy().transpose()\n",
    "y_pred = y_pred.detach().numpy().transpose()\n",
    "yTraj_test = sim.compute(p_pred)\n",
    "print(np.sum(yTraj_test-y_pred))\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
