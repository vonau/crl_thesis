{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 300\n",
    "epochs = 100\n",
    "hiddenlayers = [90]\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "learning_rate = 0.001\n",
    "time_length = 60; #seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulation\n",
    "dyn = d.PyDyn('test2.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum,3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "#x[:,0] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "y_target= torch.tensor(y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the custon Simulation Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input.shape}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        state = dyn.compute(p)\n",
    "        y_pred = torch.tensor(state.y[-3:])\n",
    "        #print(f'y_pred: {y_pred.dtype}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        #print(grad_output.shape)\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        state= dyn.compute(p)\n",
    "        dy_dp = dyn.dy_dp(state, p)\n",
    "        dy_dp = dy_dp[-3:, :]\n",
    "        #print(f'shape of dy/dp: {dy_dp.shape}')\n",
    "        #print(f'shape of grad_output: {grad_output.shape}')\n",
    "        grad_output = grad_output.unsqueeze(0)\n",
    "        \n",
    "        grad_input = torch.tensor(dy_dp).t().mm(grad_output.t()).t()\n",
    "        return grad_input\n",
    "\n",
    "Simulate = Simulate.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(ActiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(n_in, hiddenlayers[0])\n",
    "        self.H1 = nn.Linear(hiddenlayers[0], 3*time_length)\n",
    "        #self.H1 = nn.Linear(hiddenlayers[0], hiddenlayers[1])\n",
    "        #self.H2 = nn.Linear(hiddenlayers[1], 3*time_length)\n",
    "        self.P = nn.Linear(3*time_length, 3*time_length)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H1(x)\n",
    "        x = self.Relu(x)\n",
    "        #x = self.H2(x)\n",
    "        #x = self.Relu(x)\n",
    "        x = self.P(x)\n",
    "        x = self.Relu(x)\n",
    "        #x, p = Simulate(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ActiveLearn(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()  # RMSE = np.sqrt(MSE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "y_target = y_target.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:   0/100  loss: 0.36655095\nepoch:   1/100  loss: 0.67137098\nepoch:   2/100  loss: 0.76946491\nepoch:   3/100  loss: 0.29436484\nepoch:   4/100  loss: 0.27473098\nepoch:   5/100  loss: 0.24678572\nepoch:   6/100  loss: 0.25862655\nepoch:   7/100  loss: 0.24847789\nepoch:   8/100  loss: 0.21911789\nepoch:   9/100  loss: 0.22918035\nepoch:  10/100  loss: 0.26954097\nepoch:  11/100  loss: 0.21446466\nepoch:  12/100  loss: 0.20759344\nepoch:  13/100  loss: 0.16880524\nepoch:  14/100  loss: 0.14307599\nepoch:  15/100  loss: 0.12750436\nepoch:  16/100  loss: 0.10503265\nepoch:  17/100  loss: 0.08631773\nepoch:  18/100  loss: 0.07082889\nepoch:  19/100  loss: 0.05932863\nepoch:  20/100  loss: 0.04957286\nepoch:  21/100  loss: 0.04240880\nepoch:  22/100  loss: 0.03471810\nepoch:  23/100  loss: 0.02982222\nepoch:  24/100  loss: 0.02583964\nepoch:  25/100  loss: 0.03282196\nepoch:  26/100  loss: 0.02410091\nepoch:  27/100  loss: 0.02275795\nepoch:  28/100  loss: 0.02210878\nepoch:  29/100  loss: 0.03367528\nepoch:  30/100  loss: 0.02524092\nepoch:  31/100  loss: 0.02420350\nepoch:  32/100  loss: 0.02206707\nepoch:  33/100  loss: 0.02214009\nepoch:  34/100  loss: 0.02050239\nepoch:  35/100  loss: 0.01510719\nepoch:  36/100  loss: 0.01095616\nepoch:  37/100  loss: 0.03285283\nepoch:  38/100  loss: 0.03312033\nepoch:  39/100  loss: 0.02813692\nepoch:  40/100  loss: 0.01243777\nepoch:  41/100  loss: 0.00584405\nepoch:  42/100  loss: 0.00394624\nepoch:  43/100  loss: 0.00207710\nepoch:  44/100  loss: 0.00130604\nepoch:  45/100  loss: 0.00097907\nepoch:  46/100  loss: 0.00081044\nepoch:  47/100  loss: 0.00069949\nepoch:  48/100  loss: 0.00062551\nepoch:  49/100  loss: 0.00059355\nepoch:  50/100  loss: 0.00059097\nepoch:  51/100  loss: 0.00059921\nepoch:  52/100  loss: 0.00060820\nepoch:  53/100  loss: 0.00061421\nepoch:  54/100  loss: 0.00064879\nepoch:  55/100  loss: 0.00069534\nepoch:  56/100  loss: 0.00063837\nepoch:  57/100  loss: 0.00057149\nepoch:  58/100  loss: 0.00055261\nepoch:  59/100  loss: 0.00096855\nepoch:  60/100  loss: 0.00126213\nepoch:  61/100  loss: 0.00247805\nepoch:  62/100  loss: 0.00142834\nepoch:  63/100  loss: 0.00089737\nepoch:  64/100  loss: 0.00062308\nepoch:  65/100  loss: 0.01889639\nepoch:  66/100  loss: 0.00487462\nepoch:  67/100  loss: 0.00413560\nepoch:  68/100  loss: 0.00060958\nepoch:  69/100  loss: 0.00734398\nepoch:  70/100  loss: 0.00522983\nepoch:  71/100  loss: 0.00345692\nepoch:  72/100  loss: 0.00171745\nepoch:  73/100  loss: 0.00350628\nepoch:  74/100  loss: 0.00240518\nepoch:  75/100  loss: 0.00278153\nepoch:  76/100  loss: 0.00448546\nepoch:  77/100  loss: 0.00189328\nepoch:  78/100  loss: 0.00375217\nepoch:  79/100  loss: 0.00553313\nepoch:  80/100  loss: 0.00469089\nepoch:  81/100  loss: 0.00118121\nepoch:  82/100  loss: 0.00431707\nepoch:  83/100  loss: 0.00234610\nepoch:  84/100  loss: 0.00049215\nepoch:  85/100  loss: 0.00468129\nepoch:  86/100  loss: 0.00047223\nepoch:  87/100  loss: 0.00065313\nepoch:  88/100  loss: 0.00107431\nepoch:  89/100  loss: 0.00068106\nepoch:  90/100  loss: 0.00049153\nepoch:  91/100  loss: 0.00032924\nepoch:  92/100  loss: 0.00065312\nepoch:  93/100  loss: 0.01380847\nepoch:  94/100  loss: 0.00036750\nepoch:  95/100  loss: 0.00036075\nepoch:  96/100  loss: 0.00014869\nepoch:  97/100  loss: 0.00303495\nepoch:  98/100  loss: 0.00019115\nepoch:  99/100  loss: 0.00072702\nepoch: 100 loss: 0.00072702\n\nDuration: 235.132 min\n"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "y_preds= np.zeros((samplenum, 3))\n",
    "p_preds= np.zeros((samplenum, 3*time_length))\n",
    "\n",
    "#y_pred = torch.tensor(y_pred)\n",
    "for i in range(epochs):\n",
    "    for s in range(samplenum):\n",
    "        y_truth = y_target[s, :]\n",
    "        #print(y_truth.shape)\n",
    "        #y_truth = y_truth.unsqueeze(0)\n",
    "        p_pred = model(y_truth)\n",
    "        y_pred = Simulate(p_pred)\n",
    "        #print(y_pred.shape)\n",
    "        y_preds[s, :] = y_pred.detach()\n",
    "        p_preds[s, :] = p_pred.detach()\n",
    "        #loss = torch.sqrt(criterion(y_pred.float(), y_truth)) # RMSE\n",
    "        loss = criterion(y_pred.float(), y_truth) # MSE\n",
    "        #loss =sum((y_pred.float()-y_truth)**2) \n",
    "        losses.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        #Back Prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}')\n",
    "    i+=1\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.3f} min') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model saved\n"
    }
   ],
   "source": [
    "#Save Model\n",
    "\n",
    "if len(losses) == epochs*(samplenum):\n",
    "    torch.save(model.state_dict(), 'Trained_Model_300420_300s_100e_onlyZpos.pt')\n",
    "    print('Model saved')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= np.random.rand(180)\n",
    "p= torch.tensor(p)\n",
    "y_pred = Simulate(p)\n",
    "y_pred = y_pred.clone().numpy()\n",
    "\n",
    "yTraj_test = sim.compute(p_pred)\n",
    "\n",
    "print(y_pred)\n",
    "print(yTraj_test[-3:])\n",
    "print(np.sum(yTraj_test[-3:]-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Script Conversion and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.9574, 0.0000, 0.0000, 2.7701, 0.0000], grad_fn=<SliceBackward>)\n"
    }
   ],
   "source": [
    "input_example = torch.tensor(y_target[0,:])\n",
    "traced_script_module = torch.jit.trace(model, input_example)\n",
    "\n",
    "# Test the torch script\n",
    "test_input= torch.tensor([0, 2, 0.5])\n",
    "output_example = traced_script_module(test_input)\n",
    "print(output_example[-5:])\n",
    "\n",
    "# Save serialized model\n",
    "traced_script_module.save(\"CPP_example_model_latest.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bitc9de6dffaec048baa4256f94fcb6712f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}