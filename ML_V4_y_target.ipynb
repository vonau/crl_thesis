{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pydde as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "samplenum = 300\n",
    "epochs = 100\n",
    "hiddenlayers = [200]\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "learning_rate = 0.01\n",
    "time_length = 60; #seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulation\n",
    "dyn = d.PyDyn('test2.sim', time_length)\n",
    "state_init = dyn.compute(dyn.p_init)\n",
    "f = dyn.f(state_init, dyn.p_init)\n",
    "df = dyn.df_dp(state_init, dyn.p_init)\n",
    "dy = dyn.dy_dp(state_init, dyn.p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample targets only variables in z direction\n",
    "y_target = np.zeros((samplenum,3))\n",
    "y_target[:,2] = np.random.rand(samplenum)\n",
    "#x[:,0] = np.random.rand(samplenum)\n",
    "y_target[:,1] = 2\n",
    "y_target= torch.tensor(y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the custon Simulation Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        #print(f'input: {input.shape}')\n",
    "        p = input.clone().numpy().transpose()\n",
    "        state = dyn.compute(p)\n",
    "        y_pred = torch.tensor(state.y[-3:])\n",
    "        #print(f'y_pred: {y_pred.dtype}')\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return y_pred, input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, input):\n",
    "        #print(grad_output.shape)\n",
    "        input, = ctx.saved_tensors\n",
    "        p = input.clone().numpy().transpose()\n",
    "        state= dyn.compute(p)\n",
    "        dy_dp = dyn.dy_dp(state, p)\n",
    "        dy_dp = dy_dp[-3:, :]\n",
    "        #print(f'shape of dy/dp: {dy_dp.shape}')\n",
    "        #print(f'shape of grad_output: {grad_output.shape}')\n",
    "        grad_output = grad_output.unsqueeze(0)\n",
    "        \n",
    "        grad_input = torch.tensor(dy_dp).t().mm(grad_output.t()).t()\n",
    "        return grad_input, None\n",
    "\n",
    "Simulate = Simulate.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(ActiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(n_in, hiddenlayers[0])\n",
    "        self.H1 = nn.Linear(hiddenlayers[0], 3*time_length)\n",
    "        #self.H1 = nn.Linear(hiddenlayers[0], hiddenlayers[1])\n",
    "        #self.H2 = nn.Linear(hiddenlayers[1], 3*time_length)\n",
    "        self.P = nn.Linear(3*time_length, 3*time_length)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H1(x)\n",
    "        x = self.Relu(x)\n",
    "        #x = self.H2(x)\n",
    "        #x = self.Relu(x)\n",
    "        x = self.P(x)\n",
    "        x = self.Relu(x)\n",
    "        x, p = Simulate(x)\n",
    "        return x, p\n",
    "\n",
    "\n",
    "model = ActiveLearn(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()  # RMSE = np.sqrt(MSE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "y_target = y_target.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:   0/100  loss: 0.36306608\nepoch:   1/100  loss: 0.00168531\nepoch:   2/100  loss: 0.00022838\nepoch:   3/100  loss: 0.00003377\nepoch:   4/100  loss: 0.00006880\nepoch:   5/100  loss: 0.00005738\nepoch:   6/100  loss: 0.00004872\nepoch:   7/100  loss: 0.00038996\nepoch:   8/100  loss: 0.00036478\nepoch:   9/100  loss: 0.00032820\nepoch:  10/100  loss: 0.00023681\nepoch:  11/100  loss: 0.00042493\nepoch:  12/100  loss: 0.00042731\nepoch:  13/100  loss: 0.00052174\nepoch:  14/100  loss: 0.00033861\nepoch:  15/100  loss: 0.00034452\nepoch:  16/100  loss: 0.00035887\nepoch:  17/100  loss: 0.00040659\nepoch:  18/100  loss: 0.00047475\nepoch:  19/100  loss: 0.00037809\nepoch:  20/100  loss: 0.00036438\nepoch:  21/100  loss: 0.00084546\nepoch:  22/100  loss: 0.00057428\nepoch:  23/100  loss: 0.00098747\nepoch:  24/100  loss: 0.00058393\nepoch:  25/100  loss: 0.00058139\nepoch:  26/100  loss: 0.00050473\nepoch:  27/100  loss: 0.00158632\nepoch:  28/100  loss: 0.00064578\nepoch:  29/100  loss: 0.00025243\nepoch:  30/100  loss: 0.00015448\nepoch:  31/100  loss: 0.00070264\nepoch:  32/100  loss: 0.00064996\nepoch:  33/100  loss: 0.00034638\nepoch:  34/100  loss: 0.00046085\nepoch:  35/100  loss: 0.00114186\nepoch:  36/100  loss: 0.00024734\nepoch:  37/100  loss: 0.00387525\nepoch:  38/100  loss: 0.00033154\nepoch:  39/100  loss: 0.00031205\nepoch:  40/100  loss: 0.00011823\nepoch:  41/100  loss: 0.00008302\nepoch:  42/100  loss: 0.00008222\nepoch:  43/100  loss: 0.00006786\nepoch:  44/100  loss: 0.00084427\nepoch:  45/100  loss: 0.00032287\nepoch:  46/100  loss: 0.00003894\nepoch:  47/100  loss: 0.00007493\nepoch:  48/100  loss: 0.00017164\nepoch:  49/100  loss: 0.00010021\nepoch:  50/100  loss: 0.00020955\nepoch:  51/100  loss: 0.00034225\nepoch:  52/100  loss: 0.00037879\nepoch:  53/100  loss: 0.00008857\nepoch:  54/100  loss: 0.00023663\nepoch:  55/100  loss: 0.00009602\nepoch:  56/100  loss: 0.00006561\nepoch:  57/100  loss: 0.00259436\nepoch:  58/100  loss: 0.00003647\nepoch:  59/100  loss: 0.00013919\nepoch:  60/100  loss: 0.00008660\nepoch:  61/100  loss: 0.00003129\nepoch:  62/100  loss: 0.00040099\nepoch:  63/100  loss: 0.00033607\nepoch:  64/100  loss: 0.00025525\nepoch:  65/100  loss: 0.00016639\nepoch:  66/100  loss: 0.00048821\nepoch:  67/100  loss: 0.00004490\nepoch:  68/100  loss: 0.00059010\nepoch:  69/100  loss: 0.00012488\nepoch:  70/100  loss: 0.00025467\nepoch:  71/100  loss: 0.00007039\nepoch:  72/100  loss: 0.00002506\nepoch:  73/100  loss: 0.00014286\nepoch:  74/100  loss: 0.00011193\nepoch:  75/100  loss: 0.00011258\nepoch:  76/100  loss: 0.00018259\nepoch:  77/100  loss: 0.00002177\nepoch:  78/100  loss: 0.00002392\nepoch:  79/100  loss: 0.00000263\nepoch:  80/100  loss: 0.00000879\nepoch:  81/100  loss: 0.00006547\nepoch:  82/100  loss: 0.00019593\nepoch:  83/100  loss: 0.00007537\nepoch:  84/100  loss: 0.00006256\nepoch:  85/100  loss: 0.00005280\nepoch:  86/100  loss: 0.00006110\nepoch:  87/100  loss: 0.00005723\nepoch:  88/100  loss: 0.00002976\nepoch:  89/100  loss: 0.00013744\nepoch:  90/100  loss: 0.00019150\nepoch:  91/100  loss: 0.00018092\nepoch:  92/100  loss: 0.00007583\nepoch:  93/100  loss: 0.00004424\nepoch:  94/100  loss: 0.00004263\nepoch:  95/100  loss: 0.00008494\nepoch:  96/100  loss: 0.00011781\nepoch:  97/100  loss: 0.00009655\nepoch:  98/100  loss: 0.00008505\nepoch:  99/100  loss: 0.00006361\nepoch: 100 loss: 0.00006361\n\nDuration: 275.642 min\n"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "y_preds= np.zeros((samplenum, 3))\n",
    "p_preds= np.zeros((samplenum, 3*time_length))\n",
    "\n",
    "#y_pred = torch.tensor(y_pred)\n",
    "for i in range(epochs):\n",
    "    for s in range(samplenum):\n",
    "        y_truth = y_target[s, :]\n",
    "        #print(y_truth.shape)\n",
    "        #y_truth = y_truth.unsqueeze(0)\n",
    "        y_pred, p_pred = model(y_truth)\n",
    "        #print(y_pred.shape)\n",
    "        y_preds[s, :] = y_pred.detach()\n",
    "        p_preds[s, :] = p_pred.detach()\n",
    "        #loss = torch.sqrt(criterion(y_pred.float(), y_truth)) # RMSE\n",
    "        loss = criterion(y_pred.float(), y_truth) # MSE\n",
    "        #loss =sum((y_pred.float()-y_truth)**2) \n",
    "        losses.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        #Back Prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch: {i:3}/{epochs}  loss: {loss.item():10.8f}')\n",
    "    i+=1\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.3f} min') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model saved\n"
    }
   ],
   "source": [
    "#Save Model\n",
    "\n",
    "if len(losses) == epochs*(samplenum):\n",
    "    torch.save(model.state_dict(), 'Trained_Model_300420_300s_100e_onlyZpos.pt')\n",
    "    print('Model saved')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= np.random.rand(180)\n",
    "p= torch.tensor(p)\n",
    "y_pred, p_pred = Simulate(p)\n",
    "y_pred = y_pred.clone().numpy()\n",
    "\n",
    "yTraj_test = sim.compute(p_pred)\n",
    "\n",
    "print(y_pred)\n",
    "print(yTraj_test[-3:])\n",
    "print(np.sum(yTraj_test[-3:]-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Script Conversion and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16578e01869c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraced_script_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test the torch script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "input_example = torch.tensor(y_target[0,:])\n",
    "traced_script_module = torch.jit.trace(model, input_example)\n",
    "\n",
    "# Test the torch script\n",
    "test_input= torch.tensor([0, 2, 0.5])\n",
    "y, output_example = traced_script_module(test_input)\n",
    "print(output_example[-5:])\n",
    "\n",
    "# Save serialized model\n",
    "traced_script_module.save(\"CPP_example_model_latest.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}