{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "input_size: 25, output_size: 240\nShape of og_input: (21000, 25)\nShape of input: (11000, 25)\nog_input after removing failed samples: (20979, 25)\ninput after removing failed samples: (10994, 25)\nMODELS LOADED\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pydde as dde\n",
    "import os\n",
    "\n",
    "########################################\n",
    "#PARAMETERS\n",
    "nTimeSteps = 60; #seconds\n",
    "use_case = 'cube-drag'\n",
    "timestamp = '1814'\n",
    "input_size = 25\n",
    "samplenum_test = 5000\n",
    "samplenum_og = 1000\n",
    "#criterion = nn.SmoothL1Loss()  # Huber Loss\n",
    "criterion = nn.MSELoss(reduction= 'sum')  # Huber Loss\n",
    "if samplenum_og == 15000:\n",
    "    model_file_path_active = '/Users/nicovonau/Code/thesis_pytorch/Trained_Models/state_dict/Model_statedict_active_' + use_case + f'_{nTimeSteps}tsteps_latest.pt'\n",
    "    model_file_path_passive = '/Users/nicovonau/Code/thesis_pytorch/Trained_Models/state_dict/Model_statedict_passive_' + use_case + f'_{nTimeSteps}tsteps_latest.pt'\n",
    "else:\n",
    "    model_file_path_active = '/Users/nicovonau/Code/thesis_pytorch/Trained_Models/state_dict/Model_statedict_active_' + use_case + f'_{nTimeSteps}tsteps_latest_{samplenum_og}.pt'\n",
    "    model_file_path_passive = '/Users/nicovonau/Code/thesis_pytorch/Trained_Models/state_dict/Model_statedict_passive_' + use_case + f'_{nTimeSteps}tsteps_latest_{samplenum_og}.pt'\n",
    "sample_file_path = f'/Users/nicovonau/Code/thesis_pytorch/Data/Samples/data_'+ use_case + f'_{nTimeSteps}tsteps_'+ timestamp +'/'\n",
    "simulation_file_path = '/Users/nicovonau/Code/thesis_pytorch/Data/Simulations/cube-drag.sim'\n",
    "objective_file_path = f'/Users/nicovonau/Code/thesis_pytorch/Data/Objectives/cube-drag.obj'\n",
    "#print(os.listdir(sample_file_path))\n",
    "\n",
    "# set log level\n",
    "dde.set_log_level(dde.LogLevel.off)\n",
    "\n",
    "#######################################\n",
    "# LOAD SIMULATION AND OBJECTIVE FUNCTION\n",
    "dyn = dde.DynamicSequence()\n",
    "dyn.loadFile(simulation_file_path, nTimeSteps)\n",
    "p_init = np.zeros(dyn.p0.size*nTimeSteps)\n",
    "for i in range(nTimeSteps):\n",
    "\tp_init[i*dyn.p0.size : (i+1)*dyn.p0.size] = dyn.p0\n",
    "state_init = dyn.q(p_init)\n",
    "r = dyn.r(state_init, p_init)\n",
    "dr = dyn.dr_dp(state_init, p_init)\n",
    "dq = dyn.dq_dp(state_init, p_init)\n",
    "\n",
    "#########################################\n",
    "#LOAD ORIGINAL SAMPLES\n",
    "og_number_of_files = len(os.listdir(sample_file_path))-5\n",
    "with open(sample_file_path + f'data_0.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    filesize = len(data['q'])\n",
    "og_samplenum = filesize*og_number_of_files\n",
    "og_input = np.zeros((og_samplenum, input_size))\n",
    "og_loss = np.zeros(og_samplenum)\n",
    "og_iterations = np.zeros(og_samplenum)\n",
    "og_lineSearchIterations = np.zeros(og_samplenum)\n",
    "\n",
    "for filenum in range(og_number_of_files):\n",
    "    with open(sample_file_path + f'data_{filenum}.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for i, q_t in enumerate(data['q_target']):\n",
    "            og_input[filenum*filesize+i, 0:3] = np.array(q_t)\n",
    "        for i, q_i in enumerate(data['q']):\n",
    "            og_input[filenum*filesize+i, 3:9] = np.array(q_i)\n",
    "        for i, qdot_i in enumerate(data['qdot']):\n",
    "            og_input[filenum*filesize+i, 9:15] = np.array(qdot_i)\n",
    "        for i, qddot_i in enumerate(data['qddot']):\n",
    "            og_input[filenum*filesize+i, 15:21] = np.array(qddot_i)\n",
    "        for i, p_now_i in enumerate(data['p_now']):\n",
    "            og_input[filenum*filesize+i, 21:25] = np.array(p_now_i) - [og_input[filenum*filesize+i, 3],og_input[filenum*filesize+i, 5], og_input[filenum*filesize+i, 6], og_input[filenum*filesize+i, 8]]\n",
    "        for i, truth in enumerate(data['loss']):\n",
    "            og_loss[filenum*filesize+i] = np.array(truth)\n",
    "        for i, iter_ in enumerate(data['iterations']):\n",
    "            og_iterations[filenum*filesize+i] = np.array(iter_)\n",
    "        for i, line in enumerate(data['lineSearchIterations']):\n",
    "            og_lineSearchIterations[filenum*filesize+i] = np.array(line)+1\n",
    "\n",
    "\n",
    "#########################################\n",
    "#LOAD TEST SAMPLES\n",
    "number_of_files = len(os.listdir(sample_file_path + 'data_test/'))\n",
    "with open(sample_file_path+ 'data_test/' + f'data_0.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    filesize = len(data['q'])\n",
    "samplenum = filesize*number_of_files\n",
    "p = np.zeros((samplenum, dyn.nParameters*nTimeSteps))\n",
    "input = np.zeros((samplenum, input_size))\n",
    "loss = np.zeros(samplenum)\n",
    "iterations = np.zeros(samplenum)\n",
    "lineSearchIterations = np.zeros(samplenum)\n",
    "\n",
    "for filenum in range(number_of_files):\n",
    "    with open(sample_file_path + f'data_{filenum}.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for i, p_i in enumerate(data['p']):\n",
    "            p[filenum*filesize+i, :] = np.array(p_i)\n",
    "        for i, q_t in enumerate(data['q_target']):\n",
    "            input[filenum*filesize+i, 0:3] = np.array(q_t)\n",
    "        for i, q_i in enumerate(data['q']):\n",
    "            input[filenum*filesize+i, 3:9] = np.array(q_i)\n",
    "        for i, qdot_i in enumerate(data['qdot']):\n",
    "            input[filenum*filesize+i, 9:15] = np.array(qdot_i)\n",
    "        for i, qddot_i in enumerate(data['qddot']):\n",
    "            input[filenum*filesize+i, 15:21] = np.array(qddot_i)\n",
    "        for i, p_now_i in enumerate(data['p_now']):\n",
    "            input[filenum*filesize+i, 21:25] = np.array(p_now_i) - [input[filenum*filesize+i, 3], input[filenum*filesize+i, 5], input[filenum*filesize+i, 6], input[filenum*filesize+i, 8]]\n",
    "        for i, truth in enumerate(data['loss']):\n",
    "            loss[filenum*filesize+i] = np.array(truth)\n",
    "        for i, iter_ in enumerate(data['iterations']):\n",
    "            iterations[filenum*filesize+i] = np.array(iter_)\n",
    "        for i, line in enumerate(data['lineSearchIterations']):\n",
    "            lineSearchIterations[filenum*filesize+i] = np.array(line)+1\n",
    "\n",
    "        output_size = len(data['p'][0])\n",
    "\n",
    "print(f'input_size: {input_size}, output_size: {output_size}')\n",
    "print(f'Shape of og_input: {og_input.shape}')\n",
    "print(f'Shape of input: {input.shape}')\n",
    "\n",
    "#Remove zeros\n",
    "p = p[~(input == 0).all(1)]\n",
    "og_input = og_input[~(og_input == 0).all(1)]\n",
    "input = input[~(input == 0).all(1)]\n",
    "\n",
    "print(f'og_input after removing failed samples: {og_input.shape}')\n",
    "print(f'input after removing failed samples: {input.shape}')\n",
    "\n",
    "#normalize qddot\n",
    "def minmaxscale(input, extrema):\n",
    "    if extrema == None:\n",
    "        maximas= []\n",
    "        minimas= []\n",
    "        for i in range(len(input[0, :])):\n",
    "            maximas.append(np.max(input[:,i]))\n",
    "            minimas.append(np.min(input[:,i]))\n",
    "        max = np.max(maximas)\n",
    "        min = np.min(minimas)\n",
    "        extrema = np.max([max, np.linalg.norm(min)])\n",
    "        scaled = (input+extrema)/(2*extrema)\n",
    "        return scaled, extrema\n",
    "    else:\n",
    "        scaled = (input+extrema)/(2*extrema)\n",
    "        return scaled\n",
    "\n",
    "og_input[:, 15:18], extr_qddot_tran = minmaxscale(og_input[:, 15:18], None)\n",
    "og_input[:, 18:21], extr_qddot_rot = minmaxscale(og_input[:, 18:21], None)\n",
    "\n",
    "input[:, 15:18] = minmaxscale(input[:, 15:18], extr_qddot_tran)\n",
    "input[:, 18:21] = minmaxscale(input[:, 18:21], extr_qddot_rot)\n",
    "\n",
    "og_input = og_input[0:samplenum_og, :]\n",
    "input = input[0:samplenum_test, :]\n",
    "p = p[0:samplenum_test, :]\n",
    "\n",
    "data = torch.tensor(input).float()\n",
    "og_data = torch.tensor(og_input).float()\n",
    "\n",
    "################################\n",
    "#LOAD MODEL\n",
    "activeHiddenlayers = [280, 350]\n",
    "class ActiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(ActiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(n_in, activeHiddenlayers[0])\n",
    "        self.H1 = nn.Linear(activeHiddenlayers[0], activeHiddenlayers[1])\n",
    "        #self.H1 = nn.Linear(activeHiddenlayers[0], out_sz)\n",
    "        self.H2 = nn.Linear(activeHiddenlayers[1], out_sz)\n",
    "        self.L_out = nn.Linear(out_sz, out_sz)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H1(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H2(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.L_out(x)\n",
    "        return x\n",
    "\n",
    "passiveHiddenlayers = [280, 350]\n",
    "class PassiveLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, out_sz):\n",
    "        super(PassiveLearn, self).__init__()\n",
    "\n",
    "        self.L_in = nn.Linear(n_in, passiveHiddenlayers[0])\n",
    "        self.H1 = nn.Linear(passiveHiddenlayers[0], passiveHiddenlayers[1])\n",
    "        self.H2 = nn.Linear(passiveHiddenlayers[1], out_sz)\n",
    "        self.L_out = nn.Linear(out_sz, out_sz)\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.L_in(input)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H1(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.H2(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.L_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "active_model = ActiveLearn(input_size, output_size)\n",
    "passive_model = PassiveLearn(input_size, output_size)\n",
    "active_model.load_state_dict(torch.load(model_file_path_active))\n",
    "passive_model.load_state_dict(torch.load(model_file_path_passive))\n",
    "print(\"MODELS LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time through trajectory optimization: 1.3260560035705566\nTime through neural network: 0.0011179447174072266\n"
    }
   ],
   "source": [
    "############################################\n",
    "#GENERATE OPTIMIZATION\n",
    "opt = dde.Newton()\n",
    "\n",
    "####################################\n",
    "#SAMPLE STATES\n",
    "# target (0:3), q (3:9), qdot (9:15), qddot (15:21), p_now (21:25) \n",
    "start_time = time.time()\n",
    "dyn_json = json.load(open(simulation_file_path))\n",
    "objective_json = json.load(open(objective_file_path))\n",
    "obj = dde.InverseObjective(dyn)\n",
    "obj.loadJson(objective_json)\n",
    "\n",
    "#Trajectory Optimization\n",
    "p_i = opt.minimize(obj, p_init)\n",
    "print(f'Time through trajectory optimization: {(time.time() - start_time)}')\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    p_val = passive_model(data[1, :])\n",
    "print(f'Time through neural network: {(time.time() - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda39d998b0540f4e659e09acca95c25f2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}